{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# King County Homebuyer Help\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "- The key stakeholders for this analysis project are potential home buyers moving to the King County area\n",
    "- We are using a data set of recent house sales in King County from 2021-2022 to create a predictive model\n",
    "- We used predictive modeling to predict prices based on certain home features\n",
    "- Our first recommendation would to be use the tool we created to get prospective homes\n",
    "- Our second recommendation would be that once a potential home buyer does buy their home, to bolster certain features of their homes to add value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding/Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all packeges required for code below\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "kcdf = pd.read_csv('./data/kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping date column and row with null values to clean the dataframe\n",
    "kcdf = kcdf.drop(columns = 'date')\n",
    "kcdf = kcdf.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observed not all houses in dataset were actually in King County\n",
    "- Used Zip Code values to filter dataframe for only King County house sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract zipcodes from house address\n",
    "def zip_code(address):\n",
    "    x = address.split(' ')[-3]\n",
    "\n",
    "    return x.split(',')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a zip code column in the dataframe and convert to int\n",
    "kcdf['zip_code'] = kcdf['address'].apply(lambda x: zip_code(x))\n",
    "kcdf['zip_code'] = kcdf['zip_code'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From government database, we inputted all zipcodes for King County and used to filter dataframe\n",
    "kc_zips = [98001, 98002,98003, 98004,98005,98006, 98007,98008,98009, 98010, 98011, 98013, 98014,98015,98019,98022,98023,98024,98025,98027,98028,98029,98030,98031,98032,98033,98034,98035,98038,98039,98040,98041,98042,98045,98047,98050,98051,98052,98053,98054,98055,98056,98057,98058,98059,98062,98063,98064,98065,98070,98071,98072,98073,98074,98075,98077,98083,98089,98092,98093,98101,98102,98103,98104,98105,98106,98107,98108,98109,98111,98112,98113,98114,98115,98116,98117,98118,98119,98121,98122,98124,98125,98126,98127,98129,98131,98132,98133,98134,98136,98138,98139,98141,98144,98145,98146,98148,98151,98154,98155,98158,98160,98161,98164,98165,98166,98168,98170,98171,98174,98175,98177,98178,98181,98184,98185,98188,98190,98191,98194,98195,98198,98199,98224,98288]\n",
    "\n",
    "realkcdf = kcdf[kcdf['zip_code'].isin(kc_zips)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interested in adding column for distance from Amazon HQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-76edfb550a8f>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  realkcdf['location'] = list(zip(realkcdf.lat, realkcdf.long))\n"
     ]
    }
   ],
   "source": [
    "# Zipping the columns lat/long into one column called location\n",
    "realkcdf['location'] = list(zip(realkcdf.lat, realkcdf.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amazon headquarter coordinates\n",
    "amzn_coord = (47.615722, -122.339494)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take two lat/long on two locations and calculate distance in miles\n",
    "def geo_distance(coord_a, coord_b):\n",
    "    \n",
    "    return geodesic(coord_a, coord_b).miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-78d5d5f6fce4>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  realkcdf['distance_to_amazon'] = realkcdf['location'].apply(lambda x: geodesic(x, amzn_coord).miles)\n"
     ]
    }
   ],
   "source": [
    "# Creating a column for distance in miles to Amazon HQ using the location column and amazon coordinates. \n",
    "realkcdf['distance_to_amazon'] = realkcdf['location'].apply(lambda x: geodesic(x, amzn_coord).miles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using distance from Amazon HQ to filter for houses within 3 miles and remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data to have only the houses that were sold with in three miles of Amazon\n",
    "data_near_amzn = realkcdf[realkcdf['distance_to_amazon'] <= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out one of the big outliers\n",
    "data_near_amzn_filt = data_near_amzn[data_near_amzn['price'] < 10000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a pairplot to look at relationships of all numerical values\n",
    "sns.pairplot(realkcdf, corner = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See price correlated with size of the home and property, as well as number of bedrooms and bathrooms\n",
    "#### Created a Heatmap to see specific correlation values between different features of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a heatmap to look at the collinearity of dependent variables\n",
    "plt.figure(figsize = (30,15))\n",
    "sns.heatmap(realkcdf.corr(), annot = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heat map correlation displays narrowed our focus to square foot of living and number of bathrooms, showing 0.62 and 0.49 correlation respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting the relationship of the sqft of living vs the sale price\n",
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "\n",
    "x = data_near_amzn_filt['sqft_living']\n",
    "y = data_near_amzn_filt['price']\n",
    "hue = data_near_amzn_filt['bedrooms']\n",
    "size = data_near_amzn_filt['bathrooms']\n",
    "\n",
    "\n",
    "sns.scatterplot(x = x, y = y, ax=ax)\n",
    "ax.set_title('Square Feet of Living vs Price (3 Mile Range from Amazon HQ)', fontsize = 22)\n",
    "ax.set_ylabel('Price in Millions USD', fontsize = 16)\n",
    "ax.set_xlabel('Square Feet of Living', fontsize = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We observed a strong positive correlation  between the  house size and price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the number of bathrooms and their average price\n",
    "fig, ax = plt.subplots(figsize = (15,10))\n",
    "\n",
    "x = data_near_amzn_filt['bathrooms']\n",
    "y = data_near_amzn_filt['price']\n",
    "\n",
    "sns.barplot(x, y, data = realkcdf, ax = ax)\n",
    "ax.set_title('Average Price vs Bathrooms (3 Mile Range From Amazon HQ)', fontsize = 22)\n",
    "ax.set_ylabel('Price in Millions USD', fontsize = 16)\n",
    "ax.set_xlabel('Number of Bathrooms', fontsize = 16);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See a linear correlation between from average price and number of bathrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created a Multivariate Linear Regression model using numerical and non-numeric columns as features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First dealt with Oirdinal Categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists to put in the ordinal encoder\n",
    "grade_list = ['2 Substandard','3 Poor','4 Low','5 Fair','6 Low Average', '7 Average', '8 Good', '9 Better', '10 Very Good', '11 Excellent','12 Luxury','13 Mansion']\n",
    "cond_list = ['Poor', 'Fair', 'Average', 'Good', 'Very Good']\n",
    "view_list = ['NONE', 'FAIR', 'AVERAGE', 'GOOD', 'EXCELLENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encoding lists and creating an ordinal datafram\n",
    "o_enc = OrdinalEncoder(categories = [grade_list, cond_list, view_list])\n",
    "ord_df =pd.DataFrame(o_enc.fit_transform(realkcdf[['grade', 'condition', 'view']]), columns = realkcdf[['grade', 'condition', 'view']].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the realkcdf and ordinal dataframes and \n",
    "new_kcdf = pd.concat([realkcdf.reset_index().drop(columns = ['grade', 'condition', 'view']), ord_df],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrangled Nominal Categorical columns to use in regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Onehot Encoding object, apply to nominal categoricals and concatenate to main dataframe \n",
    "onehot_enc = OneHotEncoder(sparse = True, handle_unknown = 'ignore')\n",
    "nominal_cols = ['waterfront', 'greenbelt', 'nuisance','heat_source', 'sewer_system','zip_code']\n",
    "ohe_df = onehot_enc.fit_transform(new_kcdf[nominal_cols])\n",
    "nominal_df = pd.DataFrame(ohe_df.toarray(),columns = onehot_enc.get_feature_names())\n",
    "cleandf = pd.concat([new_kcdf.drop(columns = \n",
    "                ['waterfront', 'greenbelt', 'heat_source', 'sewer_system', 'zip_code', 'nuisance']), nominal_df],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Simple Model (FSM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the Linear Regression object\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting columns and using as features to train model for price\n",
    "col_select1 = realkcdf.drop(columns = ['price', 'id', 'waterfront', 'nuisance', 'waterfront', 'greenbelt', 'view', 'condition', 'grade','heat_source', 'sewer_system', 'address', 'zip_code', 'location', 'distance_to_amazon' ]).columns\n",
    "X = realkcdf[col_select1]\n",
    "y = realkcdf['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the data to the regression\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking R^2 score of the training data to see variation\n",
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking prediction of sale price on separated test data\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean absolute error\n",
    "MAE = mean_absolute_error(y_pred, y_test)\n",
    "MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observed that the coeffecient of determination is not very high and that there is a large mean absolute error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Standard Scaler to increase the model's efficacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating StandardScalar and fit to training data\n",
    "ss = StandardScaler()\n",
    "ss.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming and fitting the X_train value with standard scalar\n",
    "X_standardized_train = ss.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using standard scalar to standardize the test set\n",
    "X_standardized_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model against standardized training data and checking the R^2 value\n",
    "lr.fit(X_standardized_train, y_train)\n",
    "lr.score(X_standardized_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The R^2 value of the test standardized and the test data test sale prices\n",
    "lr.score(X_standardized_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the sale price of houses from the standardized test set\n",
    "y_predstand = lr.predict(X_standardized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the standardized Mean Absolute Error\n",
    "stand_MAE = mean_absolute_error(y_predstand, y_test)\n",
    "stand_MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of First  Simple Model\n",
    "- In our first model we predicted price based on the simple numerical data given to us without any feature engineering.\n",
    "- The R^2 value and MAE are not that great showing that our model is not a great predictor for price.\n",
    "- Next step is to put in ordinal categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sustantiating the LinearRegression\n",
    "lr2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the ordinal columns and adding them to the model\n",
    "col_select2 = new_kcdf.drop(columns = ['price', 'id', 'waterfront', 'nuisance', 'waterfront', 'greenbelt', 'heat_source', 'sewer_system', 'address', 'zip_code', 'location', 'distance_to_amazon']).columns\n",
    "X = new_kcdf[col_select2]\n",
    "y = new_kcdf['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the data to the regression\n",
    "lr2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 score of the training data\n",
    "lr2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted sales price from the test set\n",
    "y_pred = lr2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAE = mean_absolute_error(y_pred, y_test)\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning Standard Scalar\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling the X train data\n",
    "ss.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming and fitting the X_train value with standard scalar\n",
    "X_standardized_train = ss.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using standard scalar to standardize the test set\n",
    "X_standardized_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The R^2 value of the standardized train set and predicted price\n",
    "lr2.fit(X_standardized_train, y_train)\n",
    "lr2.score(X_standardized_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The R^2 value of the test standardized x values and the test price values\n",
    "lr2.score(X_standardized_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted price\n",
    "y_predstand = lr2.predict(X_standardized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean absolute error\n",
    "stand_MAE = mean_absolute_error(y_predstand, y_test)\n",
    "stand_MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of Second Model\n",
    "- In our second model we incorporated the ordinal categories into our model\n",
    "- The R^2 value increased and our MAE decreased which means our model prediction was better than our first simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the LinearRegression\n",
    "lr3 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_select = cleandf.drop(columns = ['price', 'id', 'index', 'address','sqft_garage', 'location']).columns\n",
    "X = cleandf[col_select]\n",
    "y = cleandf['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fitting the data to the regression\n",
    "lr3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 score of the training data\n",
    "lr3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Looking at the first ten predicted sales prices from the test set\n",
    "y_pred = lr3.predict(X_test)\n",
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The R^2 value of the test data\n",
    "lr3.score(X_train,y_train)\n",
    "lr3.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean absolute error of the \n",
    "MAE = mean_absolute_error(y_pred, y_test)\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning StandardScalar\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scaling the X train data\n",
    "ss.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming and fitting the X_train value with standard scalar\n",
    "X_standardized_train = ss.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the X_test set with standard Scalar\n",
    "X_standardized_test = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 value of the standardized train set with train set sale prices\n",
    "lr3.fit(X_standardized_train, y_train)\n",
    "lr3.score(X_standardized_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The R^2 value of the test standardized x values and the test price values\n",
    "lr3.score(X_standardized_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the prices of the standarized feature matrix and assigning it to ss_preds \n",
    "ss_preds3 = lr3.predict(X_standardized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking a look at the predicted prices of the standardized feature matrix\n",
    "ss_preds3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the sale price from the test set using the standard scalar feature matrix\n",
    "y_predstand3 = lr3.predict(X_standardized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_MAE = mean_absolute_error(y_predstand3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean absolute error\n",
    "stand_MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the ols modeling so its easier to see what coefficent weights are related to what independent variable\n",
    "x = cleandf.drop(columns = ['price', 'id','index', 'address', 'sqft_garage', 'lat', 'location'])\n",
    "y = cleandf['price']\n",
    "results = sm.OLS(y, sm.add_constant(x)).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Summary statistics of OLS\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predicted vs actual on the test\n",
    "sns.regplot(x = ss_preds3, y = y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of reggresion plot: \n",
    "- Plotted our model's predicted price vs actual price\n",
    "- Can see variance of prediction accuracy at different price ranges\n",
    "- See cheaper houses have a better prediction then very expensive houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of residuals of the ss_preds minus the y_test\n",
    "sns.displot(ss_preds3 - y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of distribution plot: \n",
    "- See distribution of the residuals from our model predicted price vs actual price\n",
    "- Residuals are normally distributed around 0, showing our model is an accurate predictor\n",
    "- See more negative values, showing actual sale price was great than predicted price\n",
    "    - This could be from individuals overpaying for a desirable house\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "- Our final model includes all numerical, ordinal and nominal categories from our data frame\n",
    "- Including these columns enhance the accuracy of our model\n",
    "- The R^2 value is much higher than the first two models and is a respectable value. About 65% of the variability observed in the sale price is explained by the regression model.\n",
    "- The Mean Absolute Error is also much smaller than our first model \n",
    "- Our final model is a pretty decent predictor of house prices based on certain features in King County\n",
    "- Summary table also shows the influence each category to our predicted price.\n",
    "- Some coefficients that increase house sale price include: bathrooms, sqft_living, sqft_above, sqft_basement, sqft_patio, grade, condition and view\n",
    "- As we saw from our heatmap, sqft_living and bathrooms were most significant factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "- Based on our model, we can look at the coefficents of the regression model to make recommendations to new home buyers.\n",
    "- Two realistic options to look at are the coefficents of bathrooms and sqft_living\n",
    "- If new home buyers want to increase the value/price of their home then we recommend that they build a new bathroom or build an extension to the house."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
